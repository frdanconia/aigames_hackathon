{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle \n",
    "import numpy as np\n",
    "print(tf.__version__)\n",
    "\n",
    "# callbacks = myCallback()\n",
    "# mnist = tf.keras.datasets.fashion_mnist\n",
    "# (training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(pickle.load(open('train_2C_simulation_x.pkl','rb')))\n",
    "train_y = np.array(pickle.load(open('train_y.pkl','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as sk\n",
    "\n",
    "X_train, X_test, y_train, y_test = sk.train_test_split(train_x,train_y, test_size=0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/\"\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1141 samples, validate on 562 samples\n",
      "Epoch 1/150\n",
      "1141/1141 [==============================] - 1s 451us/sample - loss: 1024.4237 - val_loss: 537.5582\n",
      "Epoch 2/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 407.1687 - val_loss: 118.8687\n",
      "Epoch 3/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 448.6573 - val_loss: 530.9003\n",
      "Epoch 4/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 466.1997 - val_loss: 669.2580\n",
      "Epoch 5/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 463.7689 - val_loss: 588.4052\n",
      "Epoch 6/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 421.5519 - val_loss: 584.6688\n",
      "Epoch 7/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 358.3937 - val_loss: 66.5595\n",
      "Epoch 8/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 319.3892 - val_loss: 536.5335\n",
      "Epoch 9/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 467.1264 - val_loss: 705.4503\n",
      "Epoch 10/150\n",
      "1141/1141 [==============================] - 0s 127us/sample - loss: 375.1104 - val_loss: 581.6504\n",
      "Epoch 11/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 445.8059 - val_loss: 563.0969\n",
      "Epoch 12/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 234.7307 - val_loss: 660.2053\n",
      "Epoch 13/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 367.3353 - val_loss: 588.8259\n",
      "Epoch 14/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 303.3563 - val_loss: 475.1126\n",
      "Epoch 15/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 462.0626 - val_loss: 279.0085\n",
      "Epoch 16/150\n",
      "1141/1141 [==============================] - 0s 126us/sample - loss: 115.6892 - val_loss: 269.6318\n",
      "Epoch 17/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 344.8201 - val_loss: 208.4018\n",
      "Epoch 18/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 256.1573 - val_loss: 438.4986\n",
      "Epoch 19/150\n",
      "1141/1141 [==============================] - 0s 129us/sample - loss: 271.0388 - val_loss: 328.4898\n",
      "Epoch 20/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 260.0871 - val_loss: 264.0993\n",
      "Epoch 21/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 235.0181 - val_loss: 310.6704\n",
      "Epoch 22/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 220.5036 - val_loss: 232.6744\n",
      "Epoch 23/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 166.4675 - val_loss: 99.4756\n",
      "Epoch 24/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 315.6662 - val_loss: 185.1069\n",
      "Epoch 25/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 184.2708 - val_loss: 61.0455\n",
      "Epoch 26/150\n",
      "1141/1141 [==============================] - 0s 127us/sample - loss: 163.1328 - val_loss: 80.7179\n",
      "Epoch 27/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 178.3351 - val_loss: 277.4332\n",
      "Epoch 28/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 193.9318 - val_loss: 115.5868\n",
      "Epoch 29/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 136.0920 - val_loss: 56.7013\n",
      "Epoch 30/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 162.3527 - val_loss: 61.0460\n",
      "Epoch 31/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 170.6733 - val_loss: 613.8413\n",
      "Epoch 32/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 61.5704 - val_loss: 13.7168\n",
      "Epoch 33/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 147.0927 - val_loss: 173.5665\n",
      "Epoch 34/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 186.4956 - val_loss: 411.0469\n",
      "Epoch 35/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 236.4168 - val_loss: 396.1984\n",
      "Epoch 36/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 217.8624 - val_loss: 246.7429\n",
      "Epoch 37/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 131.3466 - val_loss: 11.5422\n",
      "Epoch 38/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 132.0074 - val_loss: 22.6141\n",
      "Epoch 39/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 144.2584 - val_loss: 29.3197\n",
      "Epoch 40/150\n",
      "1141/1141 [==============================] - 0s 126us/sample - loss: 132.2946 - val_loss: 142.1819\n",
      "Epoch 41/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 118.9716 - val_loss: 137.5421\n",
      "Epoch 42/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 80.9032 - val_loss: 69.4829\n",
      "Epoch 43/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 86.3760 - val_loss: 127.3248\n",
      "Epoch 44/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 62.5761 - val_loss: 6.3513\n",
      "Epoch 45/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 53.6323 - val_loss: 148.6116\n",
      "Epoch 46/150\n",
      "1141/1141 [==============================] - 0s 126us/sample - loss: 76.7728 - val_loss: 162.8729\n",
      "Epoch 47/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 68.7729 - val_loss: 111.9103\n",
      "Epoch 48/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 65.1048 - val_loss: 3.2974\n",
      "Epoch 49/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 57.7968 - val_loss: 12.3749\n",
      "Epoch 50/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 63.5303 - val_loss: 75.1439\n",
      "Epoch 51/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 76.1075 - val_loss: 92.7510\n",
      "Epoch 52/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 20.3264 - val_loss: 21.4433\n",
      "Epoch 53/150\n",
      "1141/1141 [==============================] - 0s 120us/sample - loss: 9.7695 - val_loss: 5.1709\n",
      "Epoch 54/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 36.3473 - val_loss: 108.0850\n",
      "Epoch 55/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 41.3282 - val_loss: 5.0716\n",
      "Epoch 56/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 54.5240 - val_loss: 11.0668\n",
      "Epoch 57/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 13.1324 - val_loss: 36.5151\n",
      "Epoch 58/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 29.3695 - val_loss: 26.6119\n",
      "Epoch 59/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 38.8725 - val_loss: 90.4942\n",
      "Epoch 60/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 37.0590 - val_loss: 9.4874\n",
      "Epoch 61/150\n",
      "1141/1141 [==============================] - 0s 126us/sample - loss: 30.6830 - val_loss: 39.6287\n",
      "Epoch 62/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 17.7021 - val_loss: 51.5653\n",
      "Epoch 63/150\n",
      "1141/1141 [==============================] - 0s 120us/sample - loss: 34.6532 - val_loss: 46.1472\n",
      "Epoch 64/150\n",
      "1141/1141 [==============================] - 0s 120us/sample - loss: 30.8491 - val_loss: 76.0486\n",
      "Epoch 65/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 36.1945 - val_loss: 51.5386\n",
      "Epoch 66/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 28.7888 - val_loss: 23.1199\n",
      "Epoch 67/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 20.9118 - val_loss: 20.2329\n",
      "Epoch 68/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 23.9813 - val_loss: 24.0112\n",
      "Epoch 69/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 9.8284 - val_loss: 3.1700\n",
      "Epoch 70/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 16.5916 - val_loss: 7.7058\n",
      "Epoch 71/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 15.9205 - val_loss: 4.2182\n",
      "Epoch 72/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 17.1320 - val_loss: 10.6086\n",
      "Epoch 73/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 20.0762 - val_loss: 14.0336\n",
      "Epoch 74/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 24.4642 - val_loss: 14.7310\n",
      "Epoch 75/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 11.0194 - val_loss: 10.0720\n",
      "Epoch 76/150\n",
      "1141/1141 [==============================] - 0s 172us/sample - loss: 9.4325 - val_loss: 5.5857\n",
      "Epoch 77/150\n",
      "1141/1141 [==============================] - 0s 128us/sample - loss: 15.9549 - val_loss: 6.2689\n",
      "Epoch 78/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 6.5736 - val_loss: 7.6867\n",
      "Epoch 79/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 2.9592 - val_loss: 1.9696\n",
      "Epoch 80/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 2.6314 - val_loss: 3.9851\n",
      "Epoch 81/150\n",
      "1141/1141 [==============================] - 0s 126us/sample - loss: 13.0900 - val_loss: 4.5968\n",
      "Epoch 82/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 17.7430 - val_loss: 13.6343\n",
      "Epoch 83/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 11.4031 - val_loss: 50.8489\n",
      "Epoch 84/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 29.1958 - val_loss: 19.4039\n",
      "Epoch 85/150\n",
      "1141/1141 [==============================] - 0s 120us/sample - loss: 5.4007 - val_loss: 13.5925\n",
      "Epoch 86/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 12.2992 - val_loss: 21.3302\n",
      "Epoch 87/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 31.7114 - val_loss: 22.0956\n",
      "Epoch 88/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 17.1247 - val_loss: 35.8398\n",
      "Epoch 89/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 19.9941 - val_loss: 22.6468\n",
      "Epoch 90/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 10.9803 - val_loss: 6.4751\n",
      "Epoch 91/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 9.4835 - val_loss: 10.3582\n",
      "Epoch 92/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 11.0752 - val_loss: 3.1437\n",
      "Epoch 93/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 18.1337 - val_loss: 11.6317\n",
      "Epoch 94/150\n",
      "1141/1141 [==============================] - 0s 120us/sample - loss: 4.4295 - val_loss: 2.3344\n",
      "Epoch 95/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 7.8435 - val_loss: 14.9878\n",
      "Epoch 96/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 8.2360 - val_loss: 1.3551\n",
      "Epoch 97/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 1.4700 - val_loss: 0.9215\n",
      "Epoch 98/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 1.3857 - val_loss: 0.8558\n",
      "Epoch 99/150\n",
      "1141/1141 [==============================] - 0s 120us/sample - loss: 1.2896 - val_loss: 1.1669\n",
      "Epoch 100/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 1.3302 - val_loss: 0.7570\n",
      "Epoch 101/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 1.5723 - val_loss: 4.9183\n",
      "Epoch 102/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 1.7337 - val_loss: 0.9171\n",
      "Epoch 103/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.8109 - val_loss: 1.3339\n",
      "Epoch 104/150\n",
      "1141/1141 [==============================] - 0s 126us/sample - loss: 2.6217 - val_loss: 3.1077\n",
      "Epoch 105/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 7.9286 - val_loss: 2.6466\n",
      "Epoch 106/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 16.8311 - val_loss: 1.4239\n",
      "Epoch 107/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 2.0440 - val_loss: 3.2693\n",
      "Epoch 108/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 4.5939 - val_loss: 0.8291\n",
      "Epoch 109/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 1.3565 - val_loss: 0.7499\n",
      "Epoch 110/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.6810 - val_loss: 0.7134\n",
      "Epoch 111/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 0.5207 - val_loss: 0.6924\n",
      "Epoch 112/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 0.9191 - val_loss: 3.5645\n",
      "Epoch 113/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 2.0823 - val_loss: 2.9726\n",
      "Epoch 114/150\n",
      "1141/1141 [==============================] - 0s 120us/sample - loss: 3.3713 - val_loss: 4.1673\n",
      "Epoch 115/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 1.5537 - val_loss: 0.3566\n",
      "Epoch 116/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 0.6204 - val_loss: 0.4213\n",
      "Epoch 117/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.3741 - val_loss: 0.3551\n",
      "Epoch 118/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 0.9712 - val_loss: 0.9084\n",
      "Epoch 119/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.5796 - val_loss: 0.2755\n",
      "Epoch 120/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 0.5819 - val_loss: 2.7513\n",
      "Epoch 121/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 4.0281 - val_loss: 6.7136\n",
      "Epoch 122/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 9.4936 - val_loss: 18.8293\n",
      "Epoch 123/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 4.3481 - val_loss: 6.6009\n",
      "Epoch 124/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 7.0715 - val_loss: 0.7910\n",
      "Epoch 125/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 2.9820 - val_loss: 4.9439\n",
      "Epoch 126/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 7.3490 - val_loss: 10.9829\n",
      "Epoch 127/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 2.0777 - val_loss: 0.6633\n",
      "Epoch 128/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 0.6304 - val_loss: 0.5990\n",
      "Epoch 129/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 0.5734 - val_loss: 0.5513\n",
      "Epoch 130/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 0.5301 - val_loss: 0.5135\n",
      "Epoch 131/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.4954 - val_loss: 0.4826\n",
      "Epoch 132/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 0.4666 - val_loss: 0.4571\n",
      "Epoch 133/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 0.4425 - val_loss: 0.4351\n",
      "Epoch 134/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 0.4218 - val_loss: 0.4163\n",
      "Epoch 135/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 0.4038 - val_loss: 0.4001\n",
      "Epoch 136/150\n",
      "1141/1141 [==============================] - 0s 123us/sample - loss: 0.3880 - val_loss: 0.3857\n",
      "Epoch 137/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.3741 - val_loss: 0.3728\n",
      "Epoch 138/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.3616 - val_loss: 0.3615\n",
      "Epoch 139/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 0.3505 - val_loss: 0.3512\n",
      "Epoch 140/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.3405 - val_loss: 0.3422\n",
      "Epoch 141/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 0.3316 - val_loss: 0.3338\n",
      "Epoch 142/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 0.3234 - val_loss: 0.3263\n",
      "Epoch 143/150\n",
      "1141/1141 [==============================] - 0s 121us/sample - loss: 0.3160 - val_loss: 0.3195\n",
      "Epoch 144/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.3092 - val_loss: 0.3132\n",
      "Epoch 145/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.3029 - val_loss: 0.3075\n",
      "Epoch 146/150\n",
      "1141/1141 [==============================] - 0s 124us/sample - loss: 0.2973 - val_loss: 0.3023\n",
      "Epoch 147/150\n",
      "1141/1141 [==============================] - 0s 127us/sample - loss: 0.2921 - val_loss: 0.2974\n",
      "Epoch 148/150\n",
      "1141/1141 [==============================] - 0s 125us/sample - loss: 0.2872 - val_loss: 0.2931\n",
      "Epoch 149/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.2829 - val_loss: 0.2890\n",
      "Epoch 150/150\n",
      "1141/1141 [==============================] - 0s 122us/sample - loss: 0.2788 - val_loss: 0.2854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3af19d0fd0>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training_images=training_images/255.0\n",
    "#test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    " # tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "logdir = \"logs/\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.fit(X_train, y_train,validation_data=(X_test, y_test) , epochs=150,\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>353200272_Wind-direction</th>\n",
       "      <th>353200272_Air-temperature</th>\n",
       "      <th>353200272_Soil-temperature</th>\n",
       "      <th>253200080_Precipitation-sum-past-24-hrs</th>\n",
       "      <th>353200272_Precipitation-sum-past-24-hrs</th>\n",
       "      <th>253200080_Precipitation-sum-past-1-hrs</th>\n",
       "      <th>353200272_Precipitation-sum-past-1-hrs</th>\n",
       "      <th>253200080_Precipitation-sum-past-10-mts</th>\n",
       "      <th>353200272_Precipitation-sum-past-10-mts</th>\n",
       "      <th>353200272_Avg-wind-speed-past-10-mts</th>\n",
       "      <th>...</th>\n",
       "      <th>00_030_45</th>\n",
       "      <th>00_030_46</th>\n",
       "      <th>00_030_47</th>\n",
       "      <th>00_030_48</th>\n",
       "      <th>00_030_49</th>\n",
       "      <th>00_030_5</th>\n",
       "      <th>00_030_6</th>\n",
       "      <th>00_030_7</th>\n",
       "      <th>00_030_8</th>\n",
       "      <th>00_030_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-07 00:00:00</th>\n",
       "      <td>133.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.375031</td>\n",
       "      <td>6.119898</td>\n",
       "      <td>46.45077</td>\n",
       "      <td>64.884204</td>\n",
       "      <td>63.161951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.04127</td>\n",
       "      <td>1.794884</td>\n",
       "      <td>296.593073</td>\n",
       "      <td>63.994259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-07 01:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>17.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>52.375031</td>\n",
       "      <td>6.119898</td>\n",
       "      <td>46.45077</td>\n",
       "      <td>64.884204</td>\n",
       "      <td>63.161951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.04127</td>\n",
       "      <td>1.794884</td>\n",
       "      <td>296.593073</td>\n",
       "      <td>63.994259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-07 02:00:00</th>\n",
       "      <td>104.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>52.375031</td>\n",
       "      <td>6.119898</td>\n",
       "      <td>46.45077</td>\n",
       "      <td>64.884204</td>\n",
       "      <td>63.161951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.04127</td>\n",
       "      <td>1.794884</td>\n",
       "      <td>296.593073</td>\n",
       "      <td>63.994259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-07 03:00:00</th>\n",
       "      <td>123.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>17.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>52.375031</td>\n",
       "      <td>6.119898</td>\n",
       "      <td>46.45077</td>\n",
       "      <td>64.884204</td>\n",
       "      <td>63.161951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.04127</td>\n",
       "      <td>1.794884</td>\n",
       "      <td>296.593073</td>\n",
       "      <td>63.994259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-07 04:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>52.375031</td>\n",
       "      <td>6.119898</td>\n",
       "      <td>46.45077</td>\n",
       "      <td>64.884204</td>\n",
       "      <td>63.161951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.04127</td>\n",
       "      <td>1.794884</td>\n",
       "      <td>296.593073</td>\n",
       "      <td>63.994259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     353200272_Wind-direction  353200272_Air-temperature  \\\n",
       "timestamp                                                                  \n",
       "2019-06-07 00:00:00                     133.0                       19.6   \n",
       "2019-06-07 01:00:00                     138.0                       19.2   \n",
       "2019-06-07 02:00:00                     104.0                       18.2   \n",
       "2019-06-07 03:00:00                     123.0                       17.9   \n",
       "2019-06-07 04:00:00                     129.0                       18.2   \n",
       "\n",
       "                     353200272_Soil-temperature  \\\n",
       "timestamp                                         \n",
       "2019-06-07 00:00:00                        17.6   \n",
       "2019-06-07 01:00:00                        17.9   \n",
       "2019-06-07 02:00:00                        16.4   \n",
       "2019-06-07 03:00:00                        17.2   \n",
       "2019-06-07 04:00:00                        18.5   \n",
       "\n",
       "                     253200080_Precipitation-sum-past-24-hrs  \\\n",
       "timestamp                                                      \n",
       "2019-06-07 00:00:00                                      1.4   \n",
       "2019-06-07 01:00:00                                      1.4   \n",
       "2019-06-07 02:00:00                                      1.4   \n",
       "2019-06-07 03:00:00                                      1.4   \n",
       "2019-06-07 04:00:00                                      1.4   \n",
       "\n",
       "                     353200272_Precipitation-sum-past-24-hrs  \\\n",
       "timestamp                                                      \n",
       "2019-06-07 00:00:00                                      0.3   \n",
       "2019-06-07 01:00:00                                      0.3   \n",
       "2019-06-07 02:00:00                                      0.3   \n",
       "2019-06-07 03:00:00                                      0.3   \n",
       "2019-06-07 04:00:00                                      0.3   \n",
       "\n",
       "                     253200080_Precipitation-sum-past-1-hrs  \\\n",
       "timestamp                                                     \n",
       "2019-06-07 00:00:00                                     0.0   \n",
       "2019-06-07 01:00:00                                     0.0   \n",
       "2019-06-07 02:00:00                                     0.0   \n",
       "2019-06-07 03:00:00                                     0.0   \n",
       "2019-06-07 04:00:00                                     0.0   \n",
       "\n",
       "                     353200272_Precipitation-sum-past-1-hrs  \\\n",
       "timestamp                                                     \n",
       "2019-06-07 00:00:00                                     0.0   \n",
       "2019-06-07 01:00:00                                     0.0   \n",
       "2019-06-07 02:00:00                                     0.0   \n",
       "2019-06-07 03:00:00                                     0.0   \n",
       "2019-06-07 04:00:00                                     0.0   \n",
       "\n",
       "                     253200080_Precipitation-sum-past-10-mts  \\\n",
       "timestamp                                                      \n",
       "2019-06-07 00:00:00                                      0.0   \n",
       "2019-06-07 01:00:00                                      0.0   \n",
       "2019-06-07 02:00:00                                      0.0   \n",
       "2019-06-07 03:00:00                                      0.0   \n",
       "2019-06-07 04:00:00                                      0.0   \n",
       "\n",
       "                     353200272_Precipitation-sum-past-10-mts  \\\n",
       "timestamp                                                      \n",
       "2019-06-07 00:00:00                                      0.0   \n",
       "2019-06-07 01:00:00                                      0.0   \n",
       "2019-06-07 02:00:00                                      0.0   \n",
       "2019-06-07 03:00:00                                      0.0   \n",
       "2019-06-07 04:00:00                                      0.0   \n",
       "\n",
       "                     353200272_Avg-wind-speed-past-10-mts  ...  00_030_45  \\\n",
       "timestamp                                                  ...              \n",
       "2019-06-07 00:00:00                                   2.0  ...  52.375031   \n",
       "2019-06-07 01:00:00                                   1.8  ...  52.375031   \n",
       "2019-06-07 02:00:00                                   2.2  ...  52.375031   \n",
       "2019-06-07 03:00:00                                   2.5  ...  52.375031   \n",
       "2019-06-07 04:00:00                                   2.9  ...  52.375031   \n",
       "\n",
       "                     00_030_46  00_030_47  00_030_48  00_030_49  00_030_5  \\\n",
       "timestamp                                                                   \n",
       "2019-06-07 00:00:00   6.119898   46.45077  64.884204  63.161951       0.0   \n",
       "2019-06-07 01:00:00   6.119898   46.45077  64.884204  63.161951       0.0   \n",
       "2019-06-07 02:00:00   6.119898   46.45077  64.884204  63.161951       0.0   \n",
       "2019-06-07 03:00:00   6.119898   46.45077  64.884204  63.161951       0.0   \n",
       "2019-06-07 04:00:00   6.119898   46.45077  64.884204  63.161951       0.0   \n",
       "\n",
       "                     00_030_6  00_030_7    00_030_8   00_030_9  \n",
       "timestamp                                                       \n",
       "2019-06-07 00:00:00  -1.04127  1.794884  296.593073  63.994259  \n",
       "2019-06-07 01:00:00  -1.04127  1.794884  296.593073  63.994259  \n",
       "2019-06-07 02:00:00  -1.04127  1.794884  296.593073  63.994259  \n",
       "2019-06-07 03:00:00  -1.04127  1.794884  296.593073  63.994259  \n",
       "2019-06-07 04:00:00  -1.04127  1.794884  296.593073  63.994259  \n",
       "\n",
       "[5 rows x 564 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = pickle.load(open('test_2C_simulation_x.pkl','rb'))\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 1) 48.0\n"
     ]
    }
   ],
   "source": [
    "test_y = model.predict(np.array(test_x))\n",
    "print(test_y.shape, np.round(test_y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x['pred'] = np.array(np.round(test_y).reshape(504,)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.index = test_x.index.astype(str).str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x[['pred']].to_csv('test_2C_simulation_y.csv',header=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
